# -*- coding: utf-8 -*-
"""Glucose__HbA1c.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Or9Y4A9SzKTyiKm9MthxtHmG7w20y0k1

# IMPORT LIBRARIES
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder
import re
import numpy as np
import seaborn as sns #pip install seaborn
import matplotlib #pip install matplotlib
import matplotlib.pyplot as plt
import sklearn #pip install scikit-learn
from sklearn.decomposition import PCA
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score,mean_squared_error
from sklearn.linear_model import LinearRegression,SGDRegressor,Ridge,Lasso,ElasticNet
from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor
from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor, plot_tree, ExtraTreeRegressor
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
# pip install lazypredict-nightly yaparak sorun çozuldu
import lazypredict
import lazypredict.Supervised
from lazypredict.Supervised import LazyClassifier
from lazypredict.Supervised import LazyRegressor
from sklearn.neighbors import KernelDensity
from scipy.stats import yeojohnson, skew
from sklearn.preprocessing import PowerTransformer
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import GradientBoostingRegressor

df=pd.read_excel('patients_glu.xlsx') # Data import

len(df)

df.head() # Data

df.tail() # Data from tail

df.shape # 501482 rows 6 columns

"""# Data Preparation  for  ML"""

df['Kayıt Tar.'] = df['Kayıt Tar.'].dt.strftime('%m/%d/%Y')
df

df['Kayıt Tar.'] = pd.to_datetime(df['Kayıt Tar.'])
df

# Group by 'Id' and 'Kayıt Tar.' and aggregate
grouped_df = df.groupby(['Id', 'Kayıt Tar.'], as_index=False).agg({
    'Age': 'first',
    'Gender': 'first',
    'Glucose': lambda x: x.mode().iloc[0] if not x.mode().empty else None,  # Get the first mode or None
    'HbA1c': lambda x: x.mode().iloc[0] if not x.mode().empty else None     # Get the first mode or None
})

grouped_df.head()

grouped_df = grouped_df.dropna(subset=['Glucose'])
grouped_df = grouped_df.dropna(subset=['HbA1c'])
grouped_df.reset_index(drop=True, inplace=True)

grouped_df.dtypes

grouped_df['Age'] = grouped_df['Age'].apply(lambda x: 0 if '/' in str(x) else x) # correction for babies below 1 year

grouped_df = grouped_df.dropna(subset=['Age'])

# Convert 'Age' from object to integer, coercing errors to NaN
grouped_df['Age'] = pd.to_numeric(grouped_df['Age'], errors='coerce').astype('Int64')  # Using 'Int64' for nullable integers

df = grouped_df.copy()
len(df)

df.eq(0).any()

# Identify categorical columns, sözel veri içeren kolonları tespit et
categorical_cols = df.select_dtypes(include=['object']).columns
categorical_cols

df=pd.get_dummies(df, columns=['Gender'], drop_first=True)
df

df = df.dropna(subset=['Age'])

df.isnull().sum() # determine null values

df.info()

df.reset_index(drop=True, inplace=True)
df.head()

del df['Kayıt Tar.']
del df['Id']

df = df.rename(columns={
    'HbA1c': '$HbA_{1c}$'
})

sns.histplot(x=df['Glucose'],kde=True,  bins=50, color='#3498db'); # check Glucose values are normally distributed?
# Histogram with KDE for Glucose

sns.histplot(x=df['$HbA_{1c}$'],kde=True, color='#3498db', bins=50);  # check HbA1c values are normally distributed?

ist=df.describe().T  # data statistics
ist

import numpy as np
import matplotlib.pyplot as plt
from math import pi

# Step 1: Prepare the Data
labels = np.array(['Mean', 'Std', 'Min', '25%', '50%', '75%'])
age_stats = np.array([46.21, 17.73, 1.00, 32.00, 47.00, 60.00])
glucose_stats = np.array([105.65, 38.93, 4.00, 87.00, 95.00, 108.00])
hbA1c_stats = np.array([ 5.92, 1.18, 3.00, 5.30, 5.60, 6.00])

# Step 2: Set up the radar chart
num_vars = len(labels)

# Split the circle into even parts and place each label at the angle of each part
angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()

# The radar chart needs to be a closed shape
age_stats = np.concatenate((age_stats,[age_stats[0]]))
glucose_stats = np.concatenate((glucose_stats,[glucose_stats[0]]))
hbA1c_stats = np.concatenate((hbA1c_stats,[hbA1c_stats[0]]))
angles += angles[:1]

# Step 3: Plot
fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))

ax.fill(angles, age_stats, color='skyblue', alpha=0.25, label='Age')
ax.fill(angles, glucose_stats, color='salmon', alpha=0.25, label='Glucose')
ax.fill(angles, hbA1c_stats, color='lightgreen', alpha=0.25, label='HbA1c')

ax.plot(angles, age_stats, color='skyblue', linewidth=2)
ax.plot(angles, glucose_stats, color='salmon', linewidth=2)
ax.plot(angles, hbA1c_stats, color='lightgreen', linewidth=2)

# Add labels to the plot
ax.set_yticklabels([])
ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels)

# Add legend
plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))

plt.title("Radar Plot of Statistics for Age, Glucose, and HbA1c")
plt.show()

glucose_data = df['Glucose']

# Calculate the statistics
count = len(glucose_data)
mean = glucose_data.mean()
std = glucose_data.std()
min_val = glucose_data.min()
q1 = glucose_data.quantile(0.25)
median = glucose_data.median()
q3 = glucose_data.quantile(0.75)
max_val = glucose_data.max()


# Create the boxplot using Seaborn
plt.figure(figsize=(4, 6))
sns.boxplot(y=glucose_data, palette="pastel", showfliers=False)

# Add statistics as annotations on the plot lines
plt.axhline(y=mean, color='blue', linestyle=':', label='Mean')
plt.text(0.55, mean, f'Mean: {mean:.2f}', va='top', ha='left', color='blue')

#plt.axhline(y=std, color='purple', linestyle='-', label='Std')
#plt.text(0.95, std, f'Std: {std:.2f}', va='bottom', ha='left', color='purple')

#plt.axhline(y=min_val, color='red', linestyle=':', label='Min')
#plt.text(0.65, min_val, f'Min: {min_val:.2f}', va='bottom', ha='left', color='red')

plt.axhline(y=q1, color='orange', linestyle=':', label='25%')
plt.text(0.55, q1, f'25%: {q1:.2f}', va='top', ha='left', color='orange')

plt.axhline(y=median, color='blue', linestyle='-', label='Median')
plt.text(0.55, median, f'Median: {median:.2f}', va='bottom', ha='left', color='blue')

plt.axhline(y=q3, color='orange', linestyle=':', label='75%')
plt.text(0.55, q3, f'75%: {q3:.2f}', va='bottom', ha='left', color='orange')

#plt.axhline(y=max_val, color='red', linestyle=':', label='Max')
#plt.text(0.65, max_val, f'Max: {max_val:.2f}', va='bottom', ha='left', color='brown')

plt.title('Boxplot of Original Glucose Values')
plt.ylabel('Value')
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Prepare the Data
data = {
    'Statistic': [ 'Mean', 'Std', 'Min', '25%', '50%', '75%', 'Max'],
    'Age': [ 46.21, 17.73, 1.00, 32.00, 47.00, 60.00, 124.00],
    'Glucose': [ 105.65, 38.93, 4.00, 87.00, 95.00, 108.00, 759.00],
    'HbA1c': [ 5.92, 1.18, 3.00, 5.30, 5.60, 6.00, 18.40]
}

# Create a DataFrame
stats_df = pd.DataFrame(data)

# Step 2: Visualize the Data
# Melt the DataFrame for easier plotting
stats_long = pd.melt(stats_df, id_vars='Statistic', var_name='Variable', value_name='Value')

# Plot the data
plt.figure(figsize=(12, 6))
sns.barplot(x='Statistic', y='Value', hue='Variable', data=stats_long, palette='viridis')

# Customize the plot
plt.title('Statistics Comparison for Age, Glucose, and HbA1c')
plt.ylabel('Values')
plt.xlabel('Statistics')
plt.xticks(rotation=45)
plt.legend(title='Variables')
plt.tight_layout()

# Show the plot
plt.show()

# Graphical distribution of mean values
plt.figure(figsize=(6, 6))
sns.barplot(x=ist.index, y='mean', data=ist)
plt.title('Mean Statistics')
plt.xlabel('Biochemical Parameter')
plt.ylabel('Mean Values')
plt.xticks(rotation=60)
plt.show()

print(ist)

"""# Correlation of Parameters"""

df.corr(numeric_only=True) # Correlation betw columns

# Korelasyon matriksi Örneğin; Glukoz HbA1c ile çok yüksek korelasyonda 0.83
plt.figure(figsize=(5,5))
sns.heatmap(df.corr(numeric_only=True),annot=True)
plt.xticks(rotation=60)
plt.show()

abs(df.corr(numeric_only=True)['Glucose'].sort_values(ascending=False))

a=abs(df.corr(numeric_only=True)['HbA1c'].sort_values(ascending=False))   # HbA1c

plt.figure(figsize=(8, 6))
sns.barplot(x=a.index, y=a.values, palette=sns.color_palette("Blues_r", len(a)))
plt.title('Correlation of Glucose with  other Variables')
plt.xlabel('Variable')
plt.ylabel('Correlation')
plt.xticks(rotation=60)
plt.show()

df['Age'] = df['Age'].astype(int)

"""# EDA -- Exploratory Data Analysis"""

rel=sns.relplot(x='HbA1c',y='Glucose',hue='Age', data=df, alpha=0.5)
plt.xticks(rotation=45)
plt.show()

rel=sns.relplot(x='$HbA_{1c}$',y='Glucose',hue='Age', data=df)
plt.xticks(rotation=45)
plt.show()

# Scatter plot
sns.scatterplot(x='HbA1c', y='Glucose', data=df)
plt.xlabel('HbA1c')
plt.ylabel('Glucose')
plt.title('Scatter Plot of HbA1c vs Glucose ')
plt.show()

plt.figure(figsize=(3, 4))
sns.countplot(x='Gender', data=df, color='#a275ac', edgecolor='grey')
plt.xlabel('Gender', fontsize=11)
plt.ylabel('Count', fontsize=11);
#_woman

# Machine Learning for 197K data

"""# Machine Learning for 197K data"""

# TRUBA HPC : https://www.truba.gov.tr/index.php/en/main-page/
# Split DataFrame
data_chunks = np.array_split(df, 9)
models_results = []  # Sonuçları saklamak için bir liste

for idx, chunk in enumerate(data_chunks):

    # Özellikleri ve hedef sütunu seç
    X = chunk[['Age', 'HbA1c', 'Gender_woman']]  # Özellik sütunları
    y = chunk['Glucose']  # Hedef sütun

    # Eğitim ve test setlerine ayır
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # LazyRegressor kullanarak modelleri eğit
    reg = LazyRegressor()
    models, predictions = reg.fit(X_train, X_test, y_train, y_test)

    # Model sonuçlarını DataFrame'e ekle
    results_df = models.reset_index()  # İndex'i resetle
    results_df['Chunk'] = f'Chunk {idx + 1}'  # Her chunk'a isim ver

    # Sonuçları listeye ekle
    models_results.append(results_df)

# Tüm sonuçları birleştir
final_results = pd.concat(models_results, ignore_index=True)


# Sonuçları görüntüle
display(final_results)

#  the best score for each chunk
first_rows = final_results.groupby('Chunk').first().reset_index()
first_rows

# Transformations

"""# Machine Learning Data Transformation

"""

df['Log transformed'] = np.log(df['Glucose'] + 1)  # Adding 1 to avoid log(0)
df['Square-Root transformed'] = np.sqrt(df['Glucose'])
df['Box-Cox transformed'], _ = stats.boxcox(df['Glucose'] + 1)  # Adding 1 to avoid issues with zero values
df['Reciprocal transformed'] = 1 / (df['Glucose'] + 1)  # Adding 1 to avoid division by zero

df['exp_transformed'] = np.exp(df['Glucose'])
# Yeo-Johnson transformation
pt = PowerTransformer(method='yeo-johnson')
df['Yeo-Johnson transformed'] = pt.fit_transform(df[['Glucose']])

fig, axes = plt.subplots(3, 2, figsize=(15, 15))

sns.histplot(df['Glucose'], kde=True, ax=axes[0, 0], color='purple')
axes[0, 0].set_xlabel('Glucose (mg/dL)')
axes[0, 0].set_title('Original Right-Skewed Data')

sns.histplot(df['Log transformed'], kde=True, ax=axes[0, 1], color='purple')
axes[0, 1].set_title('Logarithmic Transformed')

sns.histplot(df['Square-Root transformed'], kde=True, ax=axes[1, 0], color='purple')
axes[1, 0].set_title('Square Root Transformed')

sns.histplot(df['Box-Cox transformed'], kde=True, ax=axes[1, 1], color='purple')
axes[1, 1].set_title('Box-Cox Transformed')

sns.histplot(df['Yeo-Johnson transformed'], kde=True, ax=axes[2, 0], color='purple')
axes[2, 0].set_title('Yeo-Johnson Transformed')

sns.histplot(df['Reciprocal transformed'], kde=True, ax=axes[2, 1], color='purple')
axes[2, 1].set_title('Reciprocal Transformed')
plt.tight_layout()
plt.show()

# Example columns to transform
transformed_columns = [
    'log_transformed',
    'sqrt_transformed',
    'boxcox_transformed',
    'reciprocal_transformed',
    'exp_transformed',
    'Glukoz_yeojohnson'
]

models_results = []
random_sample = df.sample(n=21000, random_state=42)
for idx, chunk in enumerate(transformed_columns):


    X = random_sample[['Age', 'HbA1c', 'Gender_woman']]
    y = random_sample[chunk]


    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


    reg = LazyRegressor()
    models, predictions = reg.fit(X_train, X_test, y_train, y_test)


    results_df = models.reset_index()  # reset Index
    results_df['Transform'] = chunk


    models_results.append(results_df)

# concat results
final_results = pd.concat(models_results, ignore_index=True)


# Sonuçları görüntüle
display(final_results)

# Different transformations give you different best models
first_rows = final_results.groupby('Transform').first().reset_index()
first_rows

X = random_sample[['Age', 'HbA1c', 'Gender_woman']]
y = random_sample['Glucose']  # target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


reg = LazyRegressor()
models, predictions = reg.fit(X_train, X_test, y_train, y_test)

models

#  Outlier detection (IQR )
Q1 = df['Glucose'].quantile(0.25)
Q3 = df['Glucose'].quantile(0.75)
IQR = Q3 - Q1


lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR


df_filtered = df[(df['Glucose'] >= lower_bound) & (df['Glucose'] <= upper_bound)]

# Kernel Density Prediction
glukoz_values = df['Glucose'].values.reshape(-1, 1)
kde = KernelDensity(kernel='gaussian', bandwidth=5).fit(glukoz_values)


x_d = np.linspace(min(glukoz_values), max(glukoz_values), 1000).reshape(-1, 1)
log_density = kde.score_samples(x_d)
density = np.exp(log_density)

# 5. Düşük yoğunluk alanlarını belirleme
density_threshold = np.percentile(density, 25)  # %25 yoğunluk eşiği
low_density_indices = np.where(density < density_threshold)[0]
low_density_glukoz_values = x_d[low_density_indices]


# Plotting the results
plt.figure(figsize=(10, 6))
plt.fill_between(x_d.flatten(), density, where=(density < density_threshold), color='violet', alpha=0.5, label='Low Density Area')
plt.plot(x_d, density, color='blue', label='KDE')
#plt.title('Kernel Density Estimation of Glucose Values')
plt.xlabel('Glucose (mg/dL)')
plt.ylabel('Density')

plt.legend()

plt.show()

# Display the results
print("Low Density Glucose values start from:", low_density_glukoz_values[0])

glukoz_values = df['Glucose'].values.reshape(-1, 1)
kde = KernelDensity(kernel='gaussian', bandwidth=5).fit(glukoz_values)

x_d = np.linspace(min(glukoz_values), max(glukoz_values), 1000).reshape(-1, 1)
log_density = kde.score_samples(x_d)
density = np.exp(log_density)

density_threshold = np.percentile(density, 25)
low_density_indices = np.where(density < density_threshold)[0]
low_density_glukoz_values = x_d[low_density_indices]


hypo_threshold = 70
hyper_threshold = 125
target_range = (70, 125)


plt.figure(figsize=(10, 6))


plt.fill_between(
    x_d.flatten(), density, where=(density < density_threshold),
    color='violet', alpha=0.5, label='Low Density Area'
)
x_d_flattened = x_d.flatten()

plt.plot(x_d, density, color='blue', label='KDE')


plt.axvspan(0, hypo_threshold, color='yellow', alpha=0.3, label='Hypoglycemia')


plt.axvspan(target_range[0], target_range[1], color='green', alpha=0.3, label='Normglycemia')


plt.axvspan(hyper_threshold, max(x_d_flattened), color='lightblue', alpha=0.3, label='Hyperglycemia')


plt.title('Kernel Density Estimation of Glucose Values with Thresholds')
plt.xlabel('Glucose Values (mmol/L)')
plt.ylabel('Density')
plt.legend()
plt.grid()
plt.show()


print("Low Density Glucose values start from:", low_density_glukoz_values[0])

from sklearn.neighbors import KernelDensity


df_filtered = df[(df['Glucose'] >= lower_bound) & (df['Glucose'] <= upper_bound)]


glukoz_values = df['Glucose'].values.reshape(-1, 1)
kde = KernelDensity(kernel='gaussian', bandwidth=5).fit(glukoz_values)


x_d = np.linspace(min(glukoz_values), max(glukoz_values), 1000).reshape(-1, 1)
log_density = kde.score_samples(x_d)
density = np.exp(log_density)

density_threshold = np.percentile(density, 25)
low_density_indices = np.where(density < density_threshold)[0]
low_density_glukoz_values = x_d[low_density_indices]


glukoz_values = df['Glucose'].values.reshape(-1, 1)


kde = KernelDensity(kernel='gaussian', bandwidth=5).fit(glukoz_values)


x_d = np.linspace(min(glukoz_values), max(glukoz_values), 1000).reshape(-1, 1)
log_density = kde.score_samples(x_d)
density = np.exp(log_density)


hypo_threshold = 70
hyper_threshold = 125
norm_range = (70, 125)


plt.figure(figsize=(12, 8))


plt.fill_between(x_d.flatten(), density, where=(x_d.flatten() < hypo_threshold),
                 hatch='//', edgecolor='cornflowerblue', facecolor='none', label='Hypoglycemia')

plt.fill_between(x_d.flatten(), density, where=((x_d.flatten() >= norm_range[0]) & (x_d.flatten() <= norm_range[1])),
                 hatch='||', edgecolor='cornflowerblue', facecolor='none', label='Normoglycemia')


plt.fill_between(x_d.flatten(), density, where=(x_d.flatten() > hyper_threshold),
                 hatch='..', edgecolor='cornflowerblue', facecolor='none', label='Hyperglycemia')

# KDE line
plt.plot(x_d, density, color='royalblue', label='KDE')


plt.xlabel('Glucose (mg/dL)')
plt.ylabel('Density')
plt.legend()
#Kernel Density Estimation with Pattern Fill

plt.show()

plt.figure(figsize=(5, 4))


x_d_zoom = np.linspace(450, max(x_d), 500).reshape(-1, 1)
log_density_zoom = kde.score_samples(x_d_zoom)
density_zoom = np.exp(log_density_zoom)


density_threshold_zoom = np.percentile(density_zoom, 25)
low_density_indices_zoom = np.where(density_zoom < density_threshold_zoom)[0]
low_density_glukoz_values_zoom = x_d_zoom[low_density_indices_zoom]


closest_index = np.argmin(np.abs(x_d_zoom - 558))


plt.fill_between(x_d_zoom.flatten()[closest_index:], density_zoom[closest_index:], color='lightblue', alpha=0.5, label='Low Density Area')
plt.plot(x_d_zoom, density_zoom, color='royalblue', label='KDE')
plt.xlabel('Glucose (mg/dL))')
plt.ylabel('Density')

plt.legend()

plt.show()

print("Low Density Glucose values start from:", low_density_glukoz_values_zoom[0])

mean_glukoz = df['Glucose'].mean()


std_dev_glukoz = df['Glucose'].std()


lower_bound = mean_glukoz - 3 * std_dev_glukoz
upper_bound = mean_glukoz + 3 * std_dev_glukoz

print(f"Glukoz için ortalama: {mean_glukoz:.2f}")
print(f"Standart sapma: {std_dev_glukoz:.2f}")
print(f"±3 standart sapma aralığı: [{lower_bound:.2f}, {upper_bound:.2f}]")

# Low density area composes % area of total
df_=df[df['Glucose'] < 550]
df_1=df[df['Glucose'] > 550]
len(df_1)

total_count = len(df)

count_below_550 = len(df[df['Glucose'] < 550])


percentage_below_550 = (count_below_550 / total_count) * 100
percentage_below_550

"""# Data Augmentation with oversampling in minority data  area"""

# Filter data from low density area
df_1 = df[df['Glucose'] > 550]

# Increase data in low density area with oversampling
n_repeats = 500
df2 = pd.concat([df] + [df_1] * n_repeats, ignore_index=True)

len(df2)

len(df)

# NEW Low density area composes % area of total
df_=df2[df2['Glucose'] < 550]
df_1=df2[df2['Glucose'] > 550]
len(df_1)

total_count = len(df2)


count_below_550 = len(df2[df2['Glucose'] < 550])


percentage_below_550 = (count_below_550 / total_count) * 100
percentage_below_550

ist2=df2.describe().T
ist2

glucose_data = df2['Glucose']

# Calculate the statistics
count = len(glucose_data)
mean = glucose_data.mean()
std = glucose_data.std()
min_val = glucose_data.min()
q1 = glucose_data.quantile(0.25)
median = glucose_data.median()
q3 = glucose_data.quantile(0.75)
max_val = glucose_data.max()


# Create the boxplot using Seaborn
plt.figure(figsize=(4, 6))
sns.boxplot(y=glucose_data, palette="pastel", showfliers=False)

# Add statistics as annotations on the plot lines
plt.axhline(y=mean, color='blue', linestyle=':', label='Mean')
plt.text(0.55, mean, f'Mean: {mean:.2f}', va='top', ha='left', color='blue')

#plt.axhline(y=std, color='purple', linestyle='-', label='Std')
#plt.text(0.95, std, f'Std: {std:.2f}', va='bottom', ha='left', color='purple')

#plt.axhline(y=min_val, color='red', linestyle=':', label='Min')
#plt.text(0.65, min_val, f'Min: {min_val:.2f}', va='bottom', ha='left', color='red')

plt.axhline(y=q1, color='blue', linestyle=':', label='25%')
plt.text(0.55, q1, f'25%: {q1:.2f}', va='top', ha='left', color='orange')

plt.axhline(y=median, color='blue', linestyle='-', label='Median')
plt.text(0.55, median, f'Median: {median:.2f}', va='bottom', ha='left', color='blue')

plt.axhline(y=q3, color='orange', linestyle=':', label='75%')
plt.text(0.55, q3, f'75%: {q3:.2f}', va='bottom', ha='left', color='orange')

#plt.axhline(y=max_val, color='red', linestyle=':', label='Max')
#plt.text(0.65, max_val, f'Max: {max_val:.2f}', va='bottom', ha='left', color='red')

plt.title('Boxplot of Augmented Glucose Values')
plt.ylabel('Value')
plt.tight_layout()
plt.show()

# Best result MLP regressor for glucose unchanged prediction
from sklearn.feature_selection import VarianceThreshold
X = df[['Age', '$HbA_{1c}$', 'Gender_woman']]  # Özellikler
y = df['Glucose']  # Hedef değişken
# Create a VarianceThreshold object with a threshold of 0.1

# Eğitim ve test setlerine ayır
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# MLPRegressor modelini tanımla
mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)

# Modeli eğit
mlp.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error, r2_score
import math

y_pred = mlp.predict(X_test)


mse = mean_squared_error(y_test, y_pred)
rmse = math.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'R^2 Score: {r2:.2f}')
print(f'Root Mean Squared Error: {rmse:.2f}')

# Traditional linear prediction method was :
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=1)
plt.text(60, 668, f'$R^2$: {r2:.2f}', color='black', fontsize=10)
plt.text(60, 643, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(60, 620, f'MSE: {mse:.2f}', color='black', fontsize=10)
plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title(f'MLP Regression')

plt.tight_layout()
plt.show()

# Lineer regression model
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)

y_pred_linear = linear_model.predict(X_test)

mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)
rmse = math.sqrt(mse_linear)


print(f'Linear Regression:')
print(f'Mean Squared Error: {mse_linear:.2f}')
print(f'R^2 Score: {r2_linear:.2f}')
print(f'Root Mean Squared Error: {rmse:.2f}')

# Traditional linear prediction method was :
plt.figure(figsize=(6, 6))
plt.scatter(y_test,  y_pred_linear, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=1)
plt.text(60, 668, f'$R^2$: {r2:.2f}', color='black', fontsize=10)
plt.text(60, 643, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(60, 620, f'MSE: {mse_linear:.2f}', color='black', fontsize=10)
plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title(f'Linear Regression')
plt.tight_layout()
plt.show()

# LOG- GB REGRESSİON

# Best result MLP regressor for glucose unchanged prediction
from sklearn.feature_selection import VarianceThreshold
X = df[['Age', '$HbA_{1c}$', 'Gender_woman']]  # Özellikler
y = df['Log transformed']  # Hedef değişken
# Create a VarianceThreshold object with a threshold of 0.1


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# GradientBoostingRegressor Model was selected from the literature
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

gbr.fit(X_train, y_train)

y_pred = gbr.predict(X_test)


mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
rmse = math.sqrt(mse )


print(f'Log-transformed GBRegression:')
print(f'Mean Squared Error: {mse:.2f}')
print(f'R^2 Score: {r2:.2f}')
print(f'Root Mean Squared Error: {rmse:.2f}')

len(y_test)

# Scatter plot with predictions
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred,  alpha=0.5)
plt.plot([min(y_test), max(y_test)],[ 3.5, max(y_test)], 'r--', lw=1)

# Annotate RMSE values on the plot
plt.text(2.2, 6.20, f'MSE: {mse:.2f}', color='black', fontsize=10)
plt.text(2.2, 6.32, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(2.2, 6.42, f'$R^2$ Score: {r2:.2f}', color='black', fontsize=10)
plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title(f'Gradient Boosting Regression' )
plt.legend()
plt.tight_layout()
plt.show()

"""# Oversampling ML

"""

# Effect of OVERSAMPLING on ML
from sklearn.feature_selection import VarianceThreshold
X = df2[['Age', '$HbA_{1c}$', 'Gender_woman']]
y = df2['Log transformed']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# GradientBoostingRegressor Model was selected from the literature
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)

# Modeli eğit
gbr.fit(X_train, y_train)

y_pred = gbr.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
rmse = math.sqrt(mse )
print(f'Root Mean Squared Error: {rmse:.2f}')
print(f'Mean Squared Error: {mse:.2f}')
print(f'$R^2$ Score: {r2:.2f}')

# Scatter plot with predictions
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred,  alpha=0.5)
plt.plot([min(y_test), max(y_test)], [3.9, max(y_test)], 'r--', lw=1)

# Annotate RMSE values on the plot
plt.text(2.7, 6.30, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(2.7,6.18, f'MSE: {mse:.2f}', color='black', fontsize=10)
plt.text(2.7,6.40, f'$R^2$ Score: {r2:.2f}', color='black', fontsize=10)


plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title('Gradient Boosting Regression on augmented data' )
plt.legend()
plt.tight_layout()
plt.show()

df2 = df2.rename(columns={ '$HbA_{1c}$': 'HbA1c'  })

df2

from lightgbm import LGBMRegressor
#df = df.rename(columns={ '$HbA_{1c}$': 'HbA1c'  })
X = df2[['Age', 'HbA1c', 'Gender_woman']]
y = df2['Log transformed']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the LGBM regressor
lgbm = LGBMRegressor(random_state=42)
lgbm.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lgbm.predict(X_test)

# Calculate the performance metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'Root Mean Squared Error: {rmse:.2f}')
print(f'R^2 Score: {r2:.2f}')

# Scatter plot with predictions
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred,  alpha=0.5)
plt.plot([min(y_test), max(y_test)], [3.9, max(y_test)], 'r--', lw=1)

# Annotate RMSE values on the plot
plt.text(2.6, 6.30, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(2.6,6.18, f'MSE: {mse:.2f}', color='black', fontsize=10)
plt.text(2.6,6.40, f'$R^2$ Score: {r2:.2f}', color='black', fontsize=10)


plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title('LGBM Regression on augmented data' )
plt.legend()
plt.tight_layout()
plt.show()

import joblib

# Save model
joblib.dump(lgbm, 'lgbm_glucose_model.pkl')

sns.histplot(x=df2['Glucose'],kde=True,  bins=50, color='#3498db'); # check Glucose values are normally distributed?
# Histogram with KDE for Glucose after oversampling

# Histogram with KDE for Glucose after oversampling
sns.histplot(x=df2['$HbA_{1c}$'],kde=True, color='#3498db', bins=50);  # check HbA1c values are normally distributed?

# Bar plot of RMSE values
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=models_2.index, x="RMSE", data=models_2)
ax.set(xlim=(0, 10))

# Bar plot of calculation time
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=models_2.index, x="Time Taken", data=models_2)
ax.set(xlim=(0, 10))

#Compare results with Classical Linear Regression

X=df2[['HbA1c']]
y=df2['Glucose']
# Eğitim ve test setlerine ayır
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Lineer regresyon modelini oluştur ve eğit
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)


# Tahminleri yap
y_pred_linear = linear_model.predict(X_test)


# Performans metriklerini hesapla
mse_linear = mean_squared_error(y_test, y_pred_linear)
r2_linear = r2_score(y_test, y_pred_linear)
rmse = math.sqrt(mse_linear)


print(f'Linear Regression:')
print(f'Mean Squared Error: {mse_linear:.2f}')
print(f'R^2 Score: {r2_linear:.2f}')
print(f'Root Mean Squared Error: {rmse:.2f}')

# Traditional linear prediction method was :
plt.figure(figsize=(6, 6))
plt.scatter(y_test,  y_pred_linear, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=1)
plt.text(50, 720, f'$R^2$: {r2_linear:.2f}', color='black', fontsize=10)
plt.text(50, 690, f'RMSE: {rmse:.2f}', color='black', fontsize=10)
plt.text(50, 660, f'MSE: {mse_linear:.2f}', color='black', fontsize=10)
plt.xlabel('Real Glucose values')
plt.ylabel('Predicted Glucose values')
plt.title(f'Linear Regression on augmented data')
plt.tight_layout()
plt.show()

"""# ML for HbA1c prediction

"""

x=df2[['Age','Glucose','Gender_woman']]
y=df2['HbA1c']

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2,random_state=42)

# GradientBoostingRegressor Model was selected from the literature
gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)


gbr.fit(x_train, y_train)

y_pred = gbr.predict(x_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'R^2 Score: {r2:.2f}')

reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
models_2, predictions = reg.fit(x_train, x_test, y_train, y_test)
print(models_2)

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=models_2.index, x="R-Squared", data=models_2)
ax.set(xlim=(0, 1))